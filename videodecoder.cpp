#include "videodecoder.h"

videoDecoder::videoDecoder(QObject *parent) : QObject(parent)
{
    initCodec();
    initVariables();
}

/***************** INIT VARIABLES AND CODECS *******************************/
void videoDecoder::initVariables(){
    formatCtx = NULL;
    imgConvertCtx = 0;
    videoCodecCtx = 0;
    videoCodec = 0;
    frame = 0;
    frameRGB = 0;
    buffer = 0;
    ok=false;
    videoFinished = false;
}

bool videoDecoder::initCodec()
{
   avcodec_register_all();
   av_register_all();

   printf("License: %s\n",avformat_license());
   printf("AVCodec version %d\n", avformat_version());
   printf("AVFormat configuration: %s\n",avformat_configuration());

   return true;
}
/****************************************************************************/

bool videoDecoder::loadVideo(QString fileName){
    lastFrameTime=0;
    lastFrameNumber=0;
    desiredFrameTime=0;
    lastFrameOk=false;

    // Open video file
    if(avformat_open_input(&formatCtx, fileName.toStdString().c_str(), NULL, NULL)!=0){
        qWarning() << "Couldn't open file";
        return false;
    }

    // Retrieve stream information
    if(avformat_find_stream_info(formatCtx, NULL)<0){
        qWarning() << "Couldn't find stream information";
        return false;
    }

    // Dump information about file onto standard error
    av_dump_format(formatCtx, 0, fileName.toStdString().c_str(), 0);

    // Find the first video stream
    videoStream=-1;
    for(unsigned i=0; i<formatCtx->nb_streams; i++)
        if(formatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO)
        {
            videoStream=i;
            break;
        }
    if(videoStream==-1){
        qWarning() << "Didn't find a video stream";
        return false;
    }

    // Get a pointer to the codec context for the video stream
    videoCodecCtx=formatCtx->streams[videoStream]->codec;

    // Find the decoder for the video stream
    videoCodec=avcodec_find_decoder(videoCodecCtx->codec_id);
    if(videoCodec==NULL){
        qWarning() << "Codec not found";
        return false;
    }

    // Open codec
    if(avcodec_open2(videoCodecCtx, videoCodec, NULL)<0){
        qWarning() << "Could not open codec";
        return false;
    }

    // Hack to correct wrong frame rates that seem to be generated by some codecs
    if(videoCodecCtx->time_base.num>1000 && videoCodecCtx->time_base.den==1){
        videoCodecCtx->time_base.den=1000;
    }
    // Allocate video frame
    frame=av_frame_alloc();

    // Allocate an AVFrame structure
    frameRGB=av_frame_alloc();
    if(frameRGB==NULL)
        return false;

    // Determine required buffer size and allocate buffer
    numBytes=avpicture_get_size(AV_PIX_FMT_RGB24, videoCodecCtx->width,videoCodecCtx->height);
    buffer=new uint8_t[numBytes];

    // Assign appropriate parts of buffer to image planes in pFrameRGB
    avpicture_fill((AVPicture *)frameRGB, buffer, AV_PIX_FMT_RGB24,
      videoCodecCtx->width, videoCodecCtx->height);

    ok=true;
    return true;
}

bool videoDecoder::readNextFrame(){
    if(av_read_frame(formatCtx, &packet)>=0)
        return true;
    else{
        videoFinished = true;
        return false;
    }
}

void videoDecoder::decodeFrame(int frameNumber){

    // Is this a packet from the video stream -> decode video frame
    int frameFinished;
    avcodec_decode_video2(videoCodecCtx,frame,&frameFinished,&packet);

    // Did we get a video frame?
    if(frameFinished){
       AVRational millisecondbase = {1, 1000};
       int f = packet.dts;
       int t = av_rescale_q(packet.dts,formatCtx->streams[videoStream]->time_base,millisecondbase);
       lastFrameOk = false;

       if(lastFrameOk==false){
          lastFrameOk=true;
          lastFrameTime=t;
          lastFrameNumber=f;
       }

       // Is this frame the desired frame?
       if(frameNumber==-1 || lastFrameNumber>=frameNumber){
          // It's the desired frame
          // Convert the image format (init the context the first time)
          int width = videoCodecCtx->width;
          int height = videoCodecCtx->height;
          imgConvertCtx = sws_getCachedContext(imgConvertCtx,width, height, videoCodecCtx->pix_fmt, width, height, AV_PIX_FMT_RGB24, SWS_BICUBIC, NULL, NULL, NULL);

          if(imgConvertCtx == NULL)
          {
             qWarning() <<"Cannot initialize the conversion context!\n";
             return;
          }

          sws_scale(imgConvertCtx, frame->data, frame->linesize, 0, height, frameRGB->data, frameRGB->linesize);

          // Convert the frame to QImage
          lastFrame=QImage(width,height,QImage::Format_RGB888);

          for(int y=0;y<height;y++)
             memcpy(lastFrame.scanLine(y),frameRGB->data[0]+y*frameRGB->linesize[0],width*3);

          // Set the time
          desiredFrameTime =av_rescale_q(frameNumber,formatCtx->streams[videoStream]->time_base,millisecondbase);
          lastFrameOk=true;
       }
    }  // frameFinished
}


/**********CLEAN AND CLOSE**************/
void videoDecoder::closeVideoAndClean()
{
   // Free the RGB image
   if(buffer)
      delete [] buffer;

   // Free the YUV frame
   if(frame)
      av_free(frame);

   // Free the RGB frame
   if(frameRGB)
      av_free(frameRGB);

   // Close the codec
   if(videoCodecCtx)
      avcodec_close(videoCodecCtx);

   // Close the video file
   if(formatCtx)
      avformat_close_input(&formatCtx);

   initVariables();
}

/**********GETTERS Y SETTERS************/

QImage videoDecoder::getFrame(){
    return lastFrame;
}

bool videoDecoder::isLastFrameOk(){
    return lastFrameOk;
}

int videoDecoder::getLastFrameTime(){
    return lastFrameTime;
}

int videoDecoder::getLastFrameNumber(){
    return lastFrameNumber;
}

bool videoDecoder::isOk(){
   return ok;
}

bool videoDecoder::isVideoFinished(){
    return videoFinished;
}

bool videoDecoder::isVideoStream(){
    return packet.stream_index==videoStream;
}
